---
title: "At a Glance Data Sources April 2019"
author: "Moises Evangelista"
date: "Prepared `r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    fig_crop: no
    toc: true
    toc_depth: 2
subtitle: Report Validation
fontsize: 11pt
header-includes:
- \usepackage{palatino}
- \renewcommand{\familydefault}{\sfdefault}
- \fontfamily{ppl}\selectfont

- \usepackage{xcolor}
- \usepackage[normalem]{ulem}
- \hypersetup{colorlinks,urlcolor=blue, linkcolor=black}
- \usepackage{float}
- \PassOptionsToPackage{obeyspaces}{url}
- \usepackage{graphicx, array, blindtext, longtable, tikz}
- \usepackage[export]{adjustbox}

---


\makeatletter 
\begingroup \lccode`+=32 \lowercase
 {\endgroup \def\Url@ObeySp{\Url@Edit\Url@String{ }{+}}}
 \def\Url@space{\penalty\Url@sppen\ }
\makeatother

```{r setup, include=FALSE}

# the latex code above is to keep spaces in file paths

knitr::opts_chunk$set(cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE,
                      #dpi = 500
                      dev = "cairo_pdf")

rm(list = ls()) #start with empty workspace

# setwd("~/GitHub/MullerReportAnalysis") # set the working directory

# list.files()
library(tidyverse)
library(magick)

library(pdftools)

options(scipen = 999)

```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r getData}

# read pdf file
# break it into pages
# ocr each page
# get pic of all 400+ pages
# do text analysis
# https://www.justice.gov/storage/report.pdf
# 
```

## Including Plots

You can also embed plots, for example:

```{r get_pageImages, echo=FALSE}

rm(list = ls()) #start with empty workspace

startTime <- Sys.time()

download.file("https://www.justice.gov/storage/report.pdf",
              destfile = "report.pdf"
              ,mode = "wb"
              ,quiet = FALSE)

# get pdf info

info <- pdf_info("report.pdf")

# count number of pages in pdf file

numberOfPageInPdf <- info[2] %>%
  unlist( use.names = FALSE)

Sys.time() - startTime # Time difference of 2.665368 mins

# create location to store pics

ifelse(!dir.exists(file.path("./pics")),dir.create(file.path("./pics")), FALSE)

startTime <- Sys.time()

all_tables <- vector("list", length = numberOfPageInPdf )

# loop for to save each page and get text info

for (i in seq_along(1:numberOfPageInPdf)) {
  
  timeDiff <- Sys.time() - startTime 
  
  print(paste(i, "of", numberOfPageInPdf
              ,as.double(timeDiff) %>% signif(5),
              units(timeDiff)))
  
  x <- image_read_pdf("report.pdf",
                      ,pages = i) %>% 
    image_reducenoise(.) %>% 
    image_despeckle()
  
  # error handling - skips to next URL if it gets an error
  result <- try(
    all_tables[[i]] <- x %>% 
      image_ocr() %>%
      as.data.frame()
    
  ); if(class(result) == "try-error") next;
  
  try(x %>% 
        image_scale(., "400") %>% #resize proportionally to width: 400px
        image_write(., path = paste0("./pics", "/pg_", i,".png")))
  
}

Sys.time() - startTime # Time difference of 1.745381 hours

rpt_text <- all_tables %>% # head(1000) %>%
  plyr::ldply(data.frame) 

rm(list = setdiff(ls(), c("rpt_text"
                          ,"numberOfPageInPdf")))

save.image(file = "rpt_text.Rdata")

```

```{r createPictWithAllpages}

rm(list = ls()) #start with empty workspace

load("rpt_text.Rdata") 

divisors <- function(x){
  # https://stackoverflow.com/questions/19465720/writing-a-function-to-calculate-divisors-in-r
  #  Vector of numberes to test against
  y <- seq_len(x)
  #  Modulo division. If remainder is 0 that number is a divisor of x so return it
  y[ x%%y == 0 ]
}

divisors(numberOfPageInPdf)

numberOfPageInPdf/32

# 32 pages long by 14 wide

# read page 1 then page 15 then page 15+15+1, ...
# read page 2 then page 16 then page 15+15+1, ...

pgs_toPop <- matrix(1:numberOfPageInPdf
                    , nrow = 14
                    , byrow = TRUE)   %>%  # fill matrix row-wise
  as_tibble()

startTime <- Sys.time()

for(i in names(pgs_toPop)){
  
  print(paste("column", i)) 
  #  df[[paste(i, 'length', sep="_")]] <- str_length(df[[i]])
  
  pages <- pgs_toPop %>% select(i) %>% as.vector() %>% unlist(use.names = FALSE)
  
  for (j in seq_along(1:length(pages))) {
    
    print(paste("page", j))
    
    x <- image_read( paste0("./pics"
                            , "/pg_"
                            , pages[j]
                            ,".png")) %>% 
      image_border("black", "1x1")
    
    if(j == 1) {
      img1 <- x 
    }
    else {
      img1 <- img1 %>% c(x)
    }
    
  }
  
  img1 <- img1 %>% image_append( stack = TRUE) %>% 
    image_scale(., "400") %>% #resize proportionally to width: 400px
    image_write( path = paste0("./pics", "/column_", i,".png"))
  
}

print(Sys.time() - startTime) # Time difference of 1.148182 mins

startTime <- Sys.time()

colpages <- list.files(recursive = TRUE, pattern = "column")

for (j in seq_along(1:length(colpages))) {
  
  print(paste("page", j))
  
  x <- image_read( colpages[j]) %>% 
    image_scale(., "400") %>% #resize proportionally to width: 200px
    # image_despeckle(., times = 2)
    image_contrast(., sharpen = 1)
  
  if(j == 1) {
    img1 <- x
  }
  else {
    img1 <- img1 %>% c(x)
  }
  
  img1 <- img1 %>%
    image_append( stack = FALSE)
} 

img1 %>% 
  image_write( path = paste0("./pics", "/all_cols.png"))

print(Sys.time() - startTime) # Time difference of 4.67948 mins

```


```{r readFinalPicPlot}

Cairo::CairoPDF(file = "//dpsssrvcrd55/rns_share/Moises/1etc_files/plotCitizenshipTrend.pdf"
                #units = "in", dpi = 150,
                ,width = 15, 
                height = 12, 
                pointsize = 10)


 ggplot() + theme_void() +
  annotation_custom(
    grob = ggplotGrob(grid::grid.raster(all_cols)),
    xmin = 0,
    xmax = 3,
    ymin = 5,
    ymax = 10
  ) 

```


```{r textAnalysis_tokens}

rm(list = ls()) #start with empty workspace

load("rpt_text.Rdata") 

library(tidytext)

library(textstem)
library(qdapDictionaries)

library(udpipe)

startTime <- Sys.time()

dl <- udpipe_download_model(language = "english-lines")
str(dl)

print(Sys.time() - startTime) 

ud_model <- udpipe_load_model(dl$file_model)

startTime <- Sys.time()

toks <- rpt_text %>% 
  select(text = 1) %>% 
  # head() %>% 
  rownames_to_column( var = "id")

toks <- udpipe_annotate(ud_model, x = toks$text, doc_id = toks$id) %>% 
  as.data.frame()

print(Sys.time() - startTime) # Time difference of 3.051517 mins

rm(list = setdiff(ls(), c("rpt_text"
                          ,"toks")))

save.image(file = "rpt_text.Rdata")

```

```{r textAnalysis_tokens}

rm(list = ls()) #start with empty workspace
 
load("rpt_text.Rdata") 

library(tidytext)

verbs <- toks %>% 
  mutate( token = gsub("[^[:alnum:]]", perl = TRUE, "", token),
          token = trimws(toupper(token))) %>% 
  filter(upos == "VERB") %>% 
  count(token) %>% 
  filter(!grepl("^THE$|TRUMP", token))



text_bigrams <- rpt_text %>%
  select(text = 1) %>% head() %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  separate(bigram, c("A", "B"), " ", extra = "merge") %>% 
  # mutate_at(vars(A, B),
  #           list(~gsub("\\s+", " ",.))) %>% 
  mutate_at(vars(A, B),
            list(~trimws(toupper(.)))) %>% 
  inner_join(verbs %>% 
               select(B = token)) %>% 
  count(A, B)


```